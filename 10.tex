\section{
 Единственность положительного собственного вектора. Применение к случайному блужданию.
}

\textbf{Необработанная версия из конспекта Константина Михайловича}

Так же бывает полезно ещё одно утверждение. 
\lm Пусть $A>0$, $\lambda$ -- максимальное по модулю собственное число. Если у матрицы $A$ есть собственный вектор $y\geq 0$, то $y$ собственный вектор для числа $\lambda$
\elm
\proof Рассмотрим матрицу $A^{\top}$. У неё есть положительный  собственный вектор $x$, соответсвующий собственному числу $\lambda$. Пусть $\mu$ -- собственное число для $y$. Тогда 
$$\lambda x^{\top}y= x^{\top}Ay=x^{\top}\mu y=\mu x^{\top}y.$$
Так как $x^{\top}y >0$, то $\lambda=\mu$.
\endproof


Вообще говоря матрица $P(G)$ имеет довольно много нулевых компонент. И, строго говоря, теорема Перрона не может быть верна для $P(G)$ всегда. Как же она может помочь? Для этого мы схитрим и немного поменяем задачу. А именно, рассмотрим матрицу $$P_{\alpha}(G)=(1-\alpha) P(G) + \alpha\tfrac{1}{n}J_n,$$
где $J_n$ -- матрица из одних единиц, а $\alpha \in (0,1)$. Тогда матрицы $P_{\alpha}(G)$ являются положительными. С точки зрения блуждающего пользователя это означает, что у него есть два режима -- первый, в котором он находится с вероятностью $1-\alpha$ -- это режим брожения по ссылкам, а второй режим -- переход на случайную страницу. Для матрицы $P_{\alpha}(G)$ выполнены условия теоремы и поэтому она имеет единственное не кратное максимальное собственное число, которое положительно и соответствующий собственный вектор положителен. Покажем, что это собственное число равно 1.

Для этого рассмотрим матрицу $P_{\alpha}(G)^{\top}$. У этой матрицы есть положительный собственный вектор $(1,\dots,1)$ с собственным числом 1. Но тогда это максимальное по модулю собственное число для $P_{\alpha}(G)^{\top}$ и следовательно для $P_{\alpha}(G)$. 

То, что у $P_{\alpha}(G)$ все собственные числа по модулю меньше единицы означает, что $P_{\alpha}(G)^kv \to cx$, при $k \to \infty$, где $x$ -- положительный вектор с собственным числом равным 1. Это позволяет приближённо найти $x$, что даёт желаемое распределение весов. Практически для этого можно взять $k\sim \log n$. Это позволяет заметно сэкономить на вычислениях по сравнению с теоретическим нахождением собственных векторов. Изучая предел $P_{\alpha}(G)$ при $\alpha \to 0$ можно получить информацию и про исходную матрицу.

